import os
import json
import re
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import markdown
from google import genai
from google.genai import types
from notion_client import Client
from github import Github

# è®¾ç½®åŒ—äº¬æ—¶åŒº
TZ_CN = ZoneInfo("Asia/Shanghai")

# 1. åŸºç¡€é…ç½®
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
DATABASE_ID = os.getenv("NOTION_DATABASE_ID")

# GitHub é…ç½®
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_REPO = os.getenv("GITHUB_REPOSITORY")  # æ ¼å¼: "username/repo"

# é‚®ç®±é…ç½® (SMTP)
EMAIL_HOST = os.getenv("EMAIL_HOST", "smtp.gmail.com")
EMAIL_PORT = int(os.getenv("EMAIL_PORT", 587))
EMAIL_USER = os.getenv("EMAIL_USER")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
NOTION_SUBSCRIBERS_DB_ID = os.getenv("NOTION_SUBSCRIBERS_DB_ID")
TEST_RECIPIENT = os.getenv("TEST_RECIPIENT")

client = genai.Client(api_key=GEMINI_API_KEY)
notion = Client(auth=NOTION_TOKEN)

def send_email_newsletter(metadata, markdown_content):
    """é€šè¿‡ SMTP å‘é€ HTML æ ¼å¼çš„ç®€æŠ¥é‚®ä»¶"""
    if not EMAIL_USER or not EMAIL_PASSWORD:
        return

    print("ğŸ“§ æ­£åœ¨å¯åŠ¨ SMTP é‚®ä»¶æ¨é€...")
    
    recipients = []
    if TEST_RECIPIENT:
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: ä»…å‘é€ç»™ {TEST_RECIPIENT}")
        recipients.append(TEST_RECIPIENT)
    elif NOTION_SUBSCRIBERS_DB_ID and notion:
        print("ğŸ‘¥ æ­£åœ¨ä» Notion è¯»å–è®¢é˜…è€…åˆ—è¡¨...")
        try:
            # æŸ¥è¯¢ Notion æ•°æ®åº“ (åˆ†é¡µè·å–æ‰€æœ‰ç”¨æˆ·)
            has_more = True
            start_cursor = None
            
            while has_more:
                # ä½¿ç”¨ Notion API 2025 (Data Sources)
                query_kwargs = {
                    "data_source_id": NOTION_SUBSCRIBERS_DB_ID,
                    "page_size": 100
                }
                if start_cursor:
                    query_kwargs["start_cursor"] = start_cursor
                
                resp = notion.data_sources.query(**query_kwargs)
                
                for page in resp.get("results", []):
                    props = page.get("properties", {})
                    email = ""
                    # å°è¯•å¯»æ‰¾å¸¸è§çš„é‚®ç®±åˆ—å (Email, é‚®ç®±, Mail)
                    for key, val in props.items():
                        if "mail" in key.lower() or "é‚®ç®±" in key:
                            # æ ¹æ® Notion å­—æ®µç±»å‹æå–æ–‡æœ¬
                            if val["type"] == "email":
                                email = val["email"]
                            elif val["type"] == "rich_text" and val["rich_text"]:
                                email = val["rich_text"][0]["text"]["content"]
                            elif val["type"] == "title" and val["title"]:
                                email = val["title"][0]["text"]["content"]
                            break
                    
                    if email and "@" in email:
                        recipients.append(email.strip())
                
                has_more = resp.get("has_more")
                start_cursor = resp.get("next_cursor")
                
            # å»é‡
            recipients = list(set(recipients))
            print(f"ğŸ‘¥ å…±è·å–åˆ° {len(recipients)} ä½è®¢é˜…è€…")
            
        except Exception as e:
            print(f"âŒ è¯»å– Notion è®¢é˜…åˆ—è¡¨å¤±è´¥: {e}")
    
    if not recipients:
        print("âš ï¸ æ²¡æœ‰æ”¶ä»¶äºº (è¯·é…ç½® TEST_RECIPIENT æˆ– æ£€æŸ¥ Notion è¿æ¥)ï¼Œè·³è¿‡å‘é€")
        return

    # å°† Markdown è½¬æ¢ä¸º HTML
    html_body = markdown.markdown(markdown_content)
    
    full_html = f"""
    <html>
    <head>
        <style>
            body {{ font-family: sans-serif; line-height: 1.6; color: #333; max-width: 800px; margin: 0 auto; padding: 20px; }}
            h1 {{ color: #007bff; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
            h2 {{ color: #333; margin-top: 30px; }}
            a {{ color: #007bff; text-decoration: none; }}
            blockquote {{ border-left: 4px solid #007bff; margin: 0; padding-left: 15px; color: #555; background: #f9f9f9; padding: 10px; }}
        </style>
    </head>
    <body>
        <div style="text-align: center; margin-bottom: 20px;">
            <p>ğŸ‘‡ ç‚¹å‡»ä¸‹æ–¹é“¾æ¥æŸ¥çœ‹å®Œæ•´æ’ç‰ˆ ğŸ‘‡</p>
            <a href="{os.getenv('mkdocs_site_url', 'https://news.helloaidev.com')}" style="background: #007bff; color: white; padding: 10px 20px; border-radius: 5px; text-decoration: none;">åœ¨æµè§ˆå™¨ä¸­é˜…è¯»</a>
        </div>
        {html_body}
        <div style="margin-top: 40px; font-size: 12px; color: #888; text-align: center;">
            <p>æœ¬é‚®ä»¶ç”± AI Daily News Brief è‡ªåŠ¨å‘é€</p>
        </div>
    </body>
    </html>
    """

    try:
        server = smtplib.SMTP(EMAIL_HOST, EMAIL_PORT)
        server.starttls()
        server.login(EMAIL_USER, EMAIL_PASSWORD)
        
        for email_addr in recipients:
            msg = MIMEMultipart()
            msg['From'] = f"AI Daily Brief <{EMAIL_USER}>"
            msg['To'] = email_addr
            date_str = datetime.now(TZ_CN).strftime('%Y-%m-%d')
            msg['Subject'] = f"ğŸ¤– {metadata.get('title')} ({date_str})"
            msg.attach(MIMEText(full_html, 'html'))
            server.send_message(msg)
            print(f"âœ… é‚®ä»¶å·²å‘é€è‡³: {email_addr}")
            
        server.quit()
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

def run_gemini3_research():
    """ä½¿ç”¨ Gemini 3 Pro è¿›è¡Œæ¯æ—¥åŠ¨æ€æ·±åº¦ç ”ç©¶"""
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Gemini 3 Pro æ·±åº¦ç ”ç©¶å¼•æ“...")
    
    current_date = datetime.now(TZ_CN).strftime('%Y-%m-%d')
    # åŠ¨æ€è·å–æ˜¨å¤©çš„æ—¥æœŸ
    yesterday = (datetime.now(TZ_CN) - timedelta(days=1)).strftime('%Y-%m-%d')

    
    # åˆ¤æ–­æ˜¯å¦ä¸ºå‘¨æœ« (5=Saturday, 6=Sunday)
    is_weekend = datetime.now(TZ_CN).weekday() >= 5
    mode_instruction = ""
    if is_weekend:
        mode_instruction = """
        ã€å‘¨æœ«ç‰¹åˆ«æ¨¡å¼ã€‘
        ä»Šå¤©æ˜¯å‘¨æœ«ï¼Œå¤§å‚å®˜æ–¹æ–°é—»å¯èƒ½è¾ƒå°‘ã€‚è¯·å°†æœç´¢é‡å¿ƒè½¬ç§»åˆ°ï¼š
        1. **æ·±åº¦æŠ€æœ¯å¸–**ï¼šReddit (r/LocalLlama, r/MachineLearning) æˆ– Hacker News ä¸Šçš„é«˜çƒ­åº¦æŠ€æœ¯è®¨è®ºã€‚
        2. **GitHub ä¹¦ç­¾**ï¼šæœ¬å‘¨å†…æ–°å‘å¸ƒä½†è¢«å¿½è§†çš„â€œå®è—â€å¼€æºé¡¹ç›®ã€‚
        3. **å®æˆ˜æ•™ç¨‹**ï¼šTwitter/X ä¸Šå¤§ä½¬åˆ†äº«çš„æœ€æ–°æ¨¡å‹å¾®è°ƒ (Fine-tuning) æˆ– RAG æœ€ä½³å®è·µã€‚
        ä¸è¦å—é™äºâ€œçªå‘æ–°é—»â€ï¼Œå¯»æ‰¾é‚£äº›â€œå€¼å¾—å¼€å‘è€…èŠ±å‘¨æœ«æ—¶é—´ç ”ç©¶â€çš„å†…å®¹ã€‚
        """
    else:
        mode_instruction = "é‡ç‚¹å…³æ³¨ï¼šOpenAI, Google, Anthropic ç­‰å·¨å¤´çš„æœ€æ–°å‘å¸ƒå’Œ ArXiv ä¸Šçš„çªç ´æ€§è®ºæ–‡ã€‚"

    # è·å–å½“å‰å¹´ä»½ç”¨äºéªŒè¯
    current_year = datetime.now(TZ_CN).year
    
    prompt = f"""
    # âš ï¸âš ï¸âš ï¸ æ—¶é—´éªŒè¯è­¦å‘Š âš ï¸âš ï¸âš ï¸
    
    å½“å‰å¹´ä»½ï¼š**{current_year} å¹´**ï¼ˆä¸æ˜¯ 2024 å¹´ï¼ï¼‰
    ä»Šå¤©å®Œæ•´æ—¥æœŸï¼š**{current_date}**ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
    
    **ä¸¥ç¦ä½¿ç”¨ 2024 å¹´æˆ–æ›´æ—©çš„ä¿¡æ¯ï¼** 
    æ‰€æœ‰æ—¥æœŸå¿…é¡»æ˜¯ {current_year} å¹´çš„ï¼Œæ ¼å¼ï¼š{current_year}-MM-DD
    
    # è§’è‰²å®šä¹‰
    ä½ æ˜¯ä¸€ä½ç«™åœ¨ AI è¡Œä¸šæœ€å‰æ²¿çš„ã€é¦–å¸­æƒ…æŠ¥å®˜ã€‘ï¼Œæ“…é•¿ä»æµ·é‡ç¢ç‰‡ä¿¡æ¯(åŒ…æ‹¬æ–°é—»ã€è®ºæ–‡ã€ç¤¾åŒºè®¨è®º)ä¸­æå–æœ€æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚
    
    # âš ï¸ å…³é”®çº¦æŸï¼šæ—¶æ•ˆæ€§æ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§
    ä»Šå¤©æ˜¯ {current_date}ï¼ˆ{current_year} å¹´ï¼ŒåŒ—äº¬æ—¶é—´ï¼‰ã€‚
    ä½ çš„æœç´¢èŒƒå›´ï¼š**{yesterday} è‡³ {current_date}**ï¼ˆæœ€è¿‘ 24 å°æ—¶ï¼‰
    
    **ä¸¥æ ¼è¦æ±‚**ï¼š
    1. åªæŠ¥é“å‘ç”Ÿåœ¨ {current_year} å¹´çš„ä¿¡æ¯
    2. æ¯ä¸ªæƒ…æŠ¥çš„æ—¶é—´å¿…é¡»æ ‡æ³¨ä¸ºï¼š{current_year}-MM-DD æ ¼å¼
    3. å¦‚æœæœç´¢ç»“æœæ˜¾ç¤ºæ˜¯ 2024 å¹´çš„ï¼Œç«‹å³ä¸¢å¼ƒ
    4. æ— æ³•ç¡®è®¤å¹´ä»½çš„ä¿¡æ¯ï¼Œç›´æ¥ä¸¢å¼ƒ
    5. ä¼˜å…ˆçº§ï¼šçœŸå®æ€§ > æ–°é²œåº¦ > å®Œæ•´æ€§
    6. ä¼˜å…ˆä½¿ç”¨è‹±æ–‡æ¥æºï¼Œè‹±æ–‡ä¿¡æ¯ä¼˜å…ˆäºä¸­æ–‡
    
    {mode_instruction}
    
    # ä½ çš„æ ¸å¿ƒä»»åŠ¡
    ä¸ºè®¢é˜…è€…æä¾›ä¸€ä»½**"é«˜ä¿¡å™ªæ¯”ã€å¤šç»´åº¦ã€å¯éªŒè¯"**çš„æƒ…æŠ¥ç®€æŠ¥ã€‚
    
    **æ•°é‡è¦æ±‚ï¼ˆå¼ºåˆ¶ï¼‰**ï¼š
    - æ ¸å¿ƒæƒ…æŠ¥ï¼šè‡³å°‘ **4 æ¡**ï¼Œæœ€å¤š 6 æ¡
    - æ¯æ¡æƒ…æŠ¥å¿…é¡»åŒ…å«ï¼šæ ‡é¢˜ã€æ¥æºã€æ—¥æœŸã€æ·±åº¦åˆ†æ
    - æå®¢æ¨èï¼šè‡³å°‘ **2 ä¸ª** GitHub é¡¹ç›®æˆ–å·¥å…·
    - åŸå§‹æ¥æºé“¾æ¥ï¼šè‡³å°‘ **5 ä¸ª** å¯éªŒè¯çš„ URL
    
    # æ·±åº¦ç ”ç©¶ç»´åº¦ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    
    ## ç¬¬ä¸€å±‚ï¼šå®˜æ–¹å‘å¸ƒä¸çªå‘äº‹ä»¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    - OpenAI, Anthropic, Google DeepMind, Meta AI çš„å®˜æ–¹åšå®¢
    - å¤§æ¨¡å‹ç‰ˆæœ¬æ›´æ–°ã€API å˜æ›´ã€å®šä»·è°ƒæ•´
    - é‡å¤§æ”¶è´­ã€èèµ„ã€äººäº‹å˜åŠ¨
    
    **æœç´¢æŒ‡ä»¤**ï¼š
    ```
    site:openai.com/blog OR site:anthropic.com OR site:deepmind.google after:{yesterday}
    "GPT" OR "Claude" OR "Gemini" after:{yesterday}
    "AI announcement" after:{yesterday}
    ```
    
    ## ç¬¬äºŒå±‚ï¼šå­¦æœ¯å‰æ²¿ï¼ˆè¿‡å» 24h çš„è®ºæ–‡ï¼‰
    - ArXiv cs.AI, cs.CL, cs.LG åˆ†ç±»ä¸‹çš„æ–°è®ºæ–‡
    - HuggingFace Papers çš„ Trending
    - Reddit r/MachineLearning çš„çƒ­é—¨è®¨è®º
    
    **æœç´¢æŒ‡ä»¤**ï¼š
    ```
    site:arxiv.org after:{yesterday} (LLM OR "large language model" OR GPT OR transformer)
    site:huggingface.co/papers after:{yesterday}
    site:reddit.com/r/MachineLearning top this week
    ```
    
    ## ç¬¬ä¸‰å±‚ï¼šå¼€å‘è€…ç¤¾åŒºä¸å®æˆ˜å·¥å…·
    - GitHub Trending (AI/ML åˆ†ç±»)
    - Reddit r/LocalLlama çš„çƒ­é—¨é¡¹ç›®
    - Hacker News é¦–é¡µå…³äº AI çš„è®¨è®º
    
    **æœç´¢æŒ‡ä»¤**ï¼š
    ```
    site:github.com/trending/python after:{yesterday}
    site:reddit.com/r/LocalLlama top today
    site:news.ycombinator.com "AI" OR "LLM" after:{yesterday}
    ```
    
    ## ç¬¬å››å±‚ï¼šè¡Œä¸šåŠ¨æ€ä¸åˆ†æ
    - VentureBeat, TechCrunch, The Verge çš„ AI æŠ¥é“
    - è¡Œä¸šåˆ†æå¸ˆçš„è§‚ç‚¹ï¼ˆa16z, Sequoia ç­‰ï¼‰
    
    **æœç´¢æŒ‡ä»¤**ï¼š
    ```
    site:venturebeat.com/ai OR site:techcrunch.com/tag/artificial-intelligence after:{yesterday}
    "AI funding" OR "AI startup" after:{yesterday}
    ```
    
    # ä¿¡æ¯éªŒè¯æ¸…å•ï¼ˆæ¯æ¡æƒ…æŠ¥å¿…é¡»é€šè¿‡ï¼‰
    âœ… èƒ½æ‰¾åˆ°åŸå§‹æ¥æºé“¾æ¥
    âœ… ä¿¡æ¯å‘å¸ƒæ—¶é—´åœ¨è¿‡å» 24h å†…
    âœ… è‡³å°‘æœ‰ 2 ä¸ªç‹¬ç«‹æ¥æºç¡®è®¤ï¼ˆå¯¹äºé‡å¤§æ–°é—»ï¼‰
    âœ… é¿å…æ¨¡ç³Šçš„æ—¶é—´è¡¨è¿°ï¼ˆå¦‚"æœ€è¿‘"ã€"ä¸ä¹…å‰"ï¼‰
    
    # è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆä¸¥æ ¼éµå®ˆï¼‰
    
    ---START_METADATA---
    {{
      "title": "ä»Šæ—¥æœ€æœ‰éœ‡æ’¼åŠ›çš„å¤´æ¡æ ‡é¢˜ï¼ˆä¸è¶…è¿‡ 30 å­—ï¼‰",
      "summary": "60-100 å­—çš„ç²¾å‡†æ‘˜è¦ï¼Œå¿…é¡»åŒ…å« 3-4 ä¸ªæ ¸å¿ƒè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹ç”¨åˆ†å·åˆ†éš”",
      "tags": ["æ ¸å¿ƒæŠ€æœ¯æ ‡ç­¾1", "æ ¸å¿ƒæŠ€æœ¯æ ‡ç­¾2", "è¡Œä¸šæ ‡ç­¾"],
      "importance": 7,
      "date": "{current_date}"
    }}
    ---END_METADATA---
    
    ---START_CONTENT---
    # ğŸ’¡ é¦–å¸­æ´å¯Ÿ (Chief Insight)
    ï¼ˆç”¨ 2-3 å¥è¯æ€»ç»“ä»Šæ—¥æ•´ä½“å±€åŠ¿ã€‚å¿…é¡»åŸºäºçœŸå®å‘ç”Ÿçš„äº‹ä»¶ï¼Œé¿å…ç©ºæ³›è¯„è®ºï¼‰
    
    ## ğŸ”¥ æ ¸å¿ƒæƒ…æŠ¥ï¼ˆ4-6 æ¡ï¼‰
    
    ### 1. [å…·ä½“äº‹ä»¶æ ‡é¢˜ - å¿…é¡»åŒ…å«å…³é”®å®ä½“åç§°]
    **æ¥æº**: [åª’ä½“åç§° + åŸæ–‡é“¾æ¥]  
    **æ—¶é—´**: {current_year}-MM-DDï¼ˆå¿…é¡»åŒ…å«å¹´ä»½ï¼æ ¼å¼ç¤ºä¾‹ï¼š{current_date}ï¼‰
    
    - **æ·±åº¦æ‹†è§£**: 
      ç”¨ 80-150 å­—è¯´æ˜ï¼šè¿™æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå‘ç”Ÿï¼Ÿæ ¸å¿ƒæŠ€æœ¯/å•†ä¸šé€»è¾‘æ˜¯ä»€ä¹ˆï¼Ÿ
      å¿…é¡»åŒ…å«å…·ä½“æ•°å­—ã€ç‰ˆæœ¬å·ã€æŠ€æœ¯ç»†èŠ‚ç­‰å¯éªŒè¯ä¿¡æ¯ã€‚
    
    - **ä¸ºä½•é‡è¦**: 
      ä¸€å¥è¯ï¼ˆ30-50 å­—ï¼‰è¯´æ˜å¯¹è¡Œä¸šçš„çŸ­æœŸå’Œé•¿æœŸå½±å“ã€‚
    
    - **ç¤¾åŒºåé¦ˆ**: 
      Redditã€Hacker Newsã€Twitter ä¸Šçš„çœŸå®è¯„è®ºæ‘˜å½•ï¼ˆå¦‚æœ‰ï¼‰ã€‚
      å¦‚æœæ²¡æœ‰ç¤¾åŒºè®¨è®ºï¼Œè¯´æ˜"æš‚æ— å¹¿æ³›è®¨è®º"ã€‚
    
    ### 2. [ç¬¬äºŒæ¡æƒ…æŠ¥...]
    ï¼ˆæ ¼å¼åŒä¸Šï¼‰
    
    ### 3. [ç¬¬ä¸‰æ¡æƒ…æŠ¥...]
    ï¼ˆæ ¼å¼åŒä¸Šï¼‰
    
    ### 4. [ç¬¬å››æ¡æƒ…æŠ¥...]
    ï¼ˆæ ¼å¼åŒä¸Šï¼‰
    
    ï¼ˆå¦‚æœæœ‰ç¬¬ 5ã€6 æ¡ï¼Œç»§ç»­æ·»åŠ ï¼‰
    
    ## ğŸ› ï¸ æå®¢æ¨èï¼ˆè‡³å°‘ 2 ä¸ªï¼‰
    - **[é¡¹ç›®å®Œæ•´åç§°](å®Œæ•´ GitHub URL)**: 
      ä¸€å¥è¯ä»‹ç»æ ¸å¿ƒåŠŸèƒ½ + ä¸ºä»€ä¹ˆå€¼å¾—å…³æ³¨ï¼ˆå¦‚ï¼šStar æ•°å¢é•¿ã€è§£å†³çš„ç—›ç‚¹ç­‰ï¼‰
      å‘å¸ƒ/æ›´æ–°æ—¶é—´ï¼š{yesterday} æˆ– {current_date}
    
    - **[é¡¹ç›®2](URL)**: ...
    
    ## ğŸ”— åŸå§‹æƒ…æŠ¥æ¥æºï¼ˆè‡³å°‘ 5 ä¸ªï¼‰
    - [å…·ä½“æ ‡é¢˜1](å®Œæ•´ URL) - å‘å¸ƒæ—¶é—´
    - [å…·ä½“æ ‡é¢˜2](å®Œæ•´ URL) - å‘å¸ƒæ—¶é—´
    - [å…·ä½“æ ‡é¢˜3](å®Œæ•´ URL) - å‘å¸ƒæ—¶é—´
    - [å…·ä½“æ ‡é¢˜4](å®Œæ•´ URL) - å‘å¸ƒæ—¶é—´
    - [å…·ä½“æ ‡é¢˜5](å®Œæ•´ URL) - å‘å¸ƒæ—¶é—´
    
    ---END_CONTENT---
    
    # æœ€åæé†’
    - å®ç¼ºæ¯‹æ»¥ï¼šå¦‚æœæŸä¸ªç»´åº¦çœŸçš„æ²¡æœ‰é‡è¦ä¿¡æ¯ï¼Œè¯šå®è¯´æ˜"ä»Šæ—¥æ— é‡å¤§æ›´æ–°"
    - é¿å…è‡†æµ‹ï¼šæ‰€æœ‰åˆ†æå¿…é¡»åŸºäºå·²å‘ç”Ÿçš„äº‹å®
    - é“¾æ¥å¿…é¡»çœŸå®ï¼šä¸è¦ç¼–é€  URLï¼Œå¦‚æœæ‰¾ä¸åˆ°é“¾æ¥å°±è¯´æ˜ä¿¡æ¯æ¥æº
    - æ—¶é—´ç²¾ç¡®ï¼šæ¯æ¡æƒ…æŠ¥å¿…é¡»æ ‡æ³¨ç¡®åˆ‡æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DD
    """

    response = client.models.generate_content(
        model='gemini-3-pro-preview', 
        contents=prompt,
        config=types.GenerateContentConfig(
            tools=[types.Tool(google_search=types.GoogleSearch())],
            thinking_config=types.ThinkingConfig(include_thoughts=True)
        )
    )
    
    # æ—¥æœŸéªŒè¯ä¸æ¸…ç†
    generated_text = response.text
    current_year = datetime.now(TZ_CN).year
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯å¹´ä»½
    if "2024" in generated_text or "2023" in generated_text:
        print(f"âš ï¸  è­¦å‘Šï¼šç”Ÿæˆçš„å†…å®¹åŒ…å«æ—§å¹´ä»½æ•°æ®ï¼Œæ­£åœ¨å°è¯•ä¿®æ­£...")
        
        # æ›¿æ¢é”™è¯¯çš„å¹´ä»½ï¼ˆä¿å®ˆå¤„ç†ï¼‰
        import re
        # æ›¿æ¢æ—¥æœŸæ ¼å¼ä¸­çš„ 2024 ä¸ºå½“å‰å¹´ä»½
        generated_text = re.sub(r'\b2024-(\d{2})-(\d{2})\b', f'{current_year}-\\1-\\2', generated_text)
        generated_text = re.sub(r'\b2023-(\d{2})-(\d{2})\b', f'{current_year}-\\1-\\2', generated_text)
        
        # æ›¿æ¢æ–‡æœ¬ä¸­çš„å¹´ä»½æåŠ
        generated_text = re.sub(r'\b2024\s*å¹´', f'{current_year} å¹´', generated_text)
        generated_text = re.sub(r'\b2023\s*å¹´', f'{current_year} å¹´', generated_text)
        
        print(f"âœ… å·²å°†å†…å®¹ä¸­çš„å¹´ä»½ä¿®æ­£ä¸º {current_year} å¹´")
    else:
        print(f"âœ… æ—¥æœŸéªŒè¯é€šè¿‡ï¼šæœªå‘ç°æ—§å¹´ä»½æ•°æ®")
    
    return generated_text

def parse_gemini_response(raw_text):
    """ä»åŸå§‹æ–‡æœ¬ä¸­æå–å…ƒæ•°æ®å’Œæ­£æ–‡å†…å®¹"""
    try:
        metadata_match = re.search(r'---START_METADATA---(.*?)---END_METADATA---', raw_text, re.DOTALL)
        content_match = re.search(r'---START_CONTENT---(.*?)---END_CONTENT---', raw_text, re.DOTALL)
        
        if metadata_match and content_match:
            json_str = metadata_match.group(1).strip()
            # æ¸…ç† JSON ä¸­å¯èƒ½åŒ…è£¹çš„ markdown ä»£ç å—æ ‡è¯†
            json_str = re.sub(r'^```json|```$', '', json_str, flags=re.MULTILINE).strip()
            metadata = json.loads(json_str)
            content = content_match.group(1).strip()
            return metadata, content
        else:
            return None, raw_text
    except Exception as e:
        print(f"âš ï¸ è§£æè§£æå‡ºé”™: {e}")
        return None, raw_text

def split_content_to_blocks(text):
    """
    å°† Markdown æ–‡æœ¬è½¬æ¢ä¸º Notion çš„ç»“æ„åŒ– Block
    æ”¯æŒï¼šHeading 1/2/3, Bullet List, Quote, Paragraph
    """
    blocks = []
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line: 
            continue
        
        # 1. Heading 1 (# )
        if line.startswith('# '):
            content = line[2:].strip()[:2000]
            blocks.append({
                "object": "block", "type": "heading_1",
                "heading_1": {"rich_text": [{"text": {"content": content}}]}
            })
        # 2. Heading 2 (## )
        elif line.startswith('## '):
            content = line[3:].strip()[:2000]
            blocks.append({
                "object": "block", "type": "heading_2",
                "heading_2": {"rich_text": [{"text": {"content": content}}]}
            })
        # 3. Heading 3 (### )
        elif line.startswith('### '):
            content = line[4:].strip()[:2000]
            blocks.append({
                "object": "block", "type": "heading_3",
                "heading_3": {"rich_text": [{"text": {"content": content}}]}
            })
        # 4. Bullet List (- or * )
        elif line.startswith('- ') or line.startswith('* '):
            content = line[2:].strip()[:2000]
            blocks.append({
                "object": "block", "type": "bulleted_list_item",
                "bulleted_list_item": {"rich_text": [{"text": {"content": content}}]}
            })
        # 5. Quote (> )
        elif line.startswith('> '):
            content = line[2:].strip()[:2000]
            blocks.append({
                "object": "block", "type": "quote",
                "quote": {"rich_text": [{"text": {"content": content}}]}
            })
        # 6. Default Paragraph
        else:
            # Notion block character limit is 2000
            content = line[:2000]
            blocks.append({
                "object": "block", "type": "paragraph",
                "paragraph": {"rich_text": [{"text": {"content": content}}]}
            })
            
    return blocks

def save_to_notion(metadata, content):
    """å°†å·²è§£æçš„å†…å®¹åŒæ­¥åˆ° Notion"""
    print("ğŸ““ æ­£åœ¨åŒæ­¥è‡³ Notion...")
    try:
        # è·å–å½“å‰æ—¥æœŸï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
        publish_date = datetime.now(TZ_CN).strftime('%Y-%m-%d')
        
        body_blocks = split_content_to_blocks(content)
        
        # æ„å»º propertiesï¼ŒåŒ…æ‹¬å‘å¸ƒæ—¥æœŸ
        properties = {
            "æ ‡é¢˜": {"title": [{"text": {"content": metadata.get('title', 'ä»Šæ—¥ AI ç®€æŠ¥')}}]},
            "ä¸€å¥è¯æ‘˜è¦": {"rich_text": [{"text": {"content": metadata.get('summary', '')}}]},
            "æ ¸å¿ƒé¢†åŸŸ": {"multi_select": [{"name": tag} for tag in metadata.get('tags', []) if tag]},
            "å‘å¸ƒæ—¥æœŸ": {"date": {"start": publish_date}}
        }
        
        notion.pages.create(
            parent={"database_id": DATABASE_ID},
            properties=properties,
            children=body_blocks[:100] 
        )
        print(f"âœ… Notion åŒæ­¥æˆåŠŸï¼å‘å¸ƒæ—¥æœŸ: {publish_date}")
    except Exception as e:
        print(f"âŒ Notion ä¿å­˜å¤±è´¥: {e}")

def update_archive_index(archive_dir):
    """éå†æ–‡ä»¶å¤¹ï¼Œç”Ÿæˆå½’æ¡£åˆ—è¡¨"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists(archive_dir):
        print(f"âš ï¸ ç›®å½• {archive_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•æ›´æ–°")
        return

    files = [f for f in os.listdir(archive_dir) if f.endswith(".md") and f != "index.md"]
    files.sort(reverse=True) # æŒ‰æ—¥æœŸå€’åºæ’
    
    index_path = os.path.join(archive_dir, "index.md")
    with open(index_path, "w", encoding="utf-8") as f:
        f.write("# ğŸ“… æ—¥æŠ¥å½’æ¡£\n\n")
        f.write("ç‚¹å‡»ä¸‹æ–¹æ—¥æœŸæŸ¥çœ‹å½“å¤©çš„ AI æ·±åº¦ç ”ç©¶ï¼š\n\n")
        for file in files:
            date_name = file.replace(".md", "")
            f.write(f"- [{date_name} çš„ AI ç®€æŠ¥]({file})\n")
    print(f"âœ… å½’æ¡£ç´¢å¼•å·²åŒæ­¥æ›´æ–°è‡³: {index_path}")

def update_homepage(metadata, content):
    """åŠ¨æ€æ›´æ–°é¦–é¡µ index.mdï¼Œå±•ç¤ºæœ€æ–°ç®€æŠ¥é¢„è§ˆ"""
    print("ğŸ  æ­£åœ¨æ›´æ–°é¦–é¡µåŠ¨æ€å†…å®¹...")
    date_str = datetime.now(TZ_CN).strftime('%Y-%m-%d')
    
    # 1. æ„é€ é¦–é¡µå†…å®¹
    # æˆ‘ä»¬åªå–æ­£æ–‡çš„å‰ 600 ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆï¼Œé¿å…é¦–é¡µè¿‡é•¿
    preview_content = content[:600] + "..." if len(content) > 600 else content
    
    homepage_template = f"""# ğŸ¤– AI æ¯æ—¥æ·±åº¦ç ”ç©¶ç®€æŠ¥

> **æœ€æ–°åŠ¨æ€ ({date_str})**: {metadata.get('summary')}

## ğŸŒŸ ä»Šæ—¥å¤´æ¡: {metadata.get('title')}

{preview_content}

---

### ğŸ”— å¿«é€Ÿé“¾æ¥
- [ğŸ“… æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š](archives/{date_str}.md)
- [ğŸ“š å¾€æœŸå†…å®¹å½’æ¡£](archives/index.md)

### ğŸ› ï¸ è®¢é˜…è¯´æ˜
æœ¬ç«™ç‚¹ç”± **Gemini 3 Pro** é©±åŠ¨ï¼Œæ¯æ—¥æ—© 8 ç‚¹é€šè¿‡ **GitHub Actions** è‡ªåŠ¨æ·±åº¦æœç´¢å…¨ç½‘ AI æƒ…æŠ¥å¹¶æ›´æ–°ã€‚

<iframe data-tally-src="https://tally.so/embed/kd9P9J?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="200" frameborder="0" marginheight="0" marginwidth="0" title="subscribe"></iframe>
<script>var d=document,w="https://tally.so/widgets/embed.js",v=function(){{"undefined"!=typeof Tally?Tally.loadEmbeds():d.querySelectorAll("iframe[data-tally-src]:not([src])").forEach((function(e){{e.src=e.dataset.tallySrc}}))}};if("undefined"!=typeof Tally)v();else if(d.querySelector('script[src="'+w+'"]')==null){{var s=d.createElement("script");s.src=w,s.onload=v,s.onerror=v,d.body.appendChild(s);}}</script>

---
*ä¸Šæ¬¡æ›´æ–°æ—¶é—´ï¼š{datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}*
"""

    # 2. å†™å…¥ docs/index.md
    with open("docs/index.md", "w", encoding="utf-8") as f:
        f.write(homepage_template)
    print("âœ… é¦–é¡µå·²æ›´æ–°ä¸ºæœ€æ–°å†…å®¹")


def save_to_markdown_file(metadata, content):
    """å°†å†…å®¹ä¿å­˜ä¸º Markdown æ–‡ä»¶ï¼Œä¾› MkDocs ä½¿ç”¨"""
    date_str = datetime.now(TZ_CN).strftime('%Y-%m-%d')
    print(f"ğŸŒ æ­£åœ¨ç”Ÿæˆç½‘é¡µæ–‡ä»¶: {date_str}.md")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    save_dir = "docs/archives"
    os.makedirs(save_dir, exist_ok=True)
    file_path = f"{save_dir}/{date_str}.md"
    
    # æ„é€ å¸¦æœ‰ Front Matter çš„å†…å®¹ï¼Œè¿™æœ‰åˆ©äº MkDocs çš„ SEO å’Œé¡µé¢æ˜¾ç¤º
    full_markdown = f"""---
title: {metadata.get('title')}
date: {date_str}
tags: {metadata.get('tags', [])}
description: {metadata.get('summary')}
---

# {metadata.get('title')}

> **æ‘˜è¦**: {metadata.get('summary')}

{content}

<div class="subscribe-card">
    <div class="subscribe-title">ğŸ“© è®¢é˜…æ¯æ—¥ AI ç®€æŠ¥</div>
    <div class="subscribe-desc">æ¯å¤©æ—©æ™¨ï¼Œå°†æœ€æ–°çš„ AI çªç ´ä¸æ·±åº¦æ´å¯Ÿç›´æ¥å‘é€åˆ°æ‚¨çš„æ”¶ä»¶ç®±ã€‚</div>
<iframe data-tally-src="https://tally.so/embed/kd9P9J?alignLeft=1&hideTitle=1&transparentBackground=1&dynamicHeight=1" loading="lazy" width="100%" height="200" frameborder="0" marginheight="0" marginwidth="0" title="subscribe"></iframe>
<script>var d=document,w="https://tally.so/widgets/embed.js",v=function(){{"undefined"!=typeof Tally?Tally.loadEmbeds():d.querySelectorAll("iframe[data-tally-src]:not([src])").forEach((function(e){{e.src=e.dataset.tallySrc}}))}};if("undefined"!=typeof Tally)v();else if(d.querySelector('script[src="'+w+'"]')==null){{var s=d.createElement("script");s.src=w,s.onload=v,s.onerror=v,d.body.appendChild(s);}}</script>
    <div style="margin-top: 10px; font-size: 0.8em; opacity: 0.7;">æˆ–è€…å›å¤ GitHub Issue è¿›è¡Œè¯„è®ºäº’åŠ¨</div>
</div>

---
*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}*
"""

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(full_markdown)
    print(f"âœ… ç½‘é¡µæ–‡ä»¶å·²ä¿å­˜è‡³: {file_path}")

def publish_to_github_issue(metadata, content):
    """å°†ç®€æŠ¥å‘å¸ƒä¸ºæ‚¨ GitHub ä»“åº“çš„ Issueï¼Œå®ç°é‚®ä»¶æ¨é€è®¢é˜…"""
    if not GITHUB_TOKEN or not GITHUB_REPO:
        print("âš ï¸ æœªé…ç½® GITHUB_TOKEN æˆ– GITHUB_REPOSITORYï¼Œè·³è¿‡ Issue å‘å¸ƒ")
        return

    print("ğŸ“§ æ­£åœ¨å‘å¸ƒ GitHub Issue...")
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(GITHUB_REPO)
        
        # æ„é€  Issue æ ‡é¢˜å’Œæ­£æ–‡
        date_str = datetime.now(TZ_CN).strftime('%Y-%m-%d')
        issue_title = f"{date_str} | {metadata.get('title')}"
        
        # åœ¨æ­£æ–‡é¡¶éƒ¨åŠ ä¸ŠåŸæ–‡é“¾æ¥ï¼Œå¢åŠ å¯¼æµ
        issue_body = f"""
> **æ‘˜è¦**: {metadata.get('summary')}

[ğŸ‘‰ ç‚¹å‡»æŸ¥çœ‹å®Œæ•´æ’ç‰ˆæŠ¥å‘Š](https://cxyac.github.io/AI-Daily-News-Brief/archives/{date_str}/)

---

{content}

---
*æœ¬æŠ¥å‘Šç”± AI Agent è‡ªåŠ¨ç”Ÿæˆï¼Œå›å¤æœ¬ Issue å¯å‚ä¸è®¨è®ºã€‚*
"""
        repo.create_issue(title=issue_title, body=issue_body, labels=["daily-brief"])
        print(f"âœ… GitHub Issue å·²å‘å¸ƒï¼š{issue_title}")
    except Exception as e:
        print(f"âŒ GitHub Issue å‘å¸ƒå¤±è´¥: {e}")

if __name__ == "__main__":
    if not GEMINI_API_KEY:
        print("âŒ é”™è¯¯: GEMINI_API_KEY æœªè®¾ç½®")
        exit(1)

    # 1. è¿è¡Œ AI ç ”ç©¶
    raw_report = run_gemini3_research()
    
    # 2. è§£æå†…å®¹
    meta, body = parse_gemini_response(raw_report)
    if not meta:
        meta = {"title": f"AI æ·±åº¦ç®€æŠ¥ - {datetime.now(TZ_CN).strftime('%Y-%m-%d')}", "summary": "ä»Šæ—¥æƒ…æŠ¥å·²é€è¾¾", "tags": ["AI"]}

    # 3. å­˜å‚¨å½“å¤©è¯¦æƒ…é¡µ (.md æ–‡ä»¶)
    save_to_markdown_file(meta, body) 

    # 4. æ›´æ–°â€œç´¢å¼•ç›®å½•â€ (è®© Archives é¡µé¢å‡ºç°æ–°é“¾æ¥)
    update_archive_index("docs/archives") 

    # 5. æ›´æ–°â€œç½‘ç«™é¦–é¡µâ€ (è®©é¦–é¡µå±•ç¤ºä»Šå¤©çš„é¢„è§ˆ)
    update_homepage(meta, body)

    # 6. åŒæ­¥ Notion (å¯é€‰å¤‡ä»½)
    if NOTION_TOKEN and DATABASE_ID:
        save_to_notion(meta, body)

    # 7. å‘å¸ƒ GitHub Issue (ä½œä¸ºé‚®ä»¶è®¢é˜…æ¸ é“)
    publish_to_github_issue(meta, body)

    # 8. SMTP é‚®ä»¶æ¨é€ (æ–°å¢)
    send_email_newsletter(meta, body)